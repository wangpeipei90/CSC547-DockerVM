#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
file_patterns=c("output_launch_docker_1.txt.*.dat$","output_launch_docker_2.txt.*.dat$","output_launch_docker_3.txt.*.dat$")
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_docker",name1,sep=".");
metrics=append(metrics,name1);
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,58,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_docker_null_metric=null_metric;
output_launch_docker_metrics=metrics;
setwd(old);
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
file_patterns=c("output_launch_dockerhadoop_1.txt.*.dat$","output_launch_dockerhadoop_2.txt.*.dat$","output_launch_dockerhadoop_3.txt.*.dat$")
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_dockerhadoop",name1,sep=".");
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
metrics=append(metrics,name1);
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,58,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_dockerhadoop_null_metric=null_metric;
output_launch_dockerhadoop_metrics=metrics;
setwd(old);
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
#file_patterns=c("output_launch_dockerhadoopprogram_1.txt.*.dat$","output_launch_dockerhadoopprogram_2.txt.*.dat$","output_launch_dockerhadoopprogram_3.txt.*.dat$","output_launch_dockerhadoopprogram_4.txt.*.dat$")
file_patterns=c("output_launch_dockerhadoopprogram_1.txt.*.dat$","output_launch_dockerhadoopprogram_2.txt.*.dat$","output_launch_dockerhadoopprogram_4.txt.*.dat$")
#discard experiment 3
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_dockerhadoopprogram",name1,sep=".");
metrics=append(metrics,name1);
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,178,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_dockerhadoopprogram_null_metric=null_metric;
output_launch_dockerhadoopprogram_metrics=metrics;
setwd(old);
t4=output_launch_dockerhadoopprogram_null_metric;
t3=output_launch_dockerhadoop_null_metric;
t2=output_launch_docker_null_metric;
t1=output_empty_null_metric=null_metric;
m1=output_empty_metrics;
m2=output_launch_docker_metrics;
m3=output_launch_dockerhadoop_metrics;
m4=output_launch_dockerhadoopprogram_metrics;
null_metrics=Reduce(intersect,list(t1,t2,t3,t4);
null_metrics=Reduce(intersect,list(t1,t2,t3,t4));
null_metrics
m1==m2
m2=m3
m3==m4
m4==m1
diff(null_metrics,m)
m=m1
diff(null_metrics,m)
Set.Diff(m,null_metrics)
setdiff(m,null_metrics)
used_metrics= setdiff(m,null_metrics);
null_metrics
null_metric=null_metrics[1]
null_metric
file_patterns=c(paste(null_metric,"$",sep=""),paste(null_metric,".png$",sep=""))
file_patterns
for(file_pattern in file_patterns){
#data_files=list.files(path=basedir,pattern=file_pattern);
rm(list=ls(pattern=file_pattern));
}
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
t4=output_launch_dockerhadoopprogram_null_metric;
t3=output_launch_dockerhadoop_null_metric;
t2=output_launch_docker_null_metric;
t1=output_empty_null_metric=null_metric;
m1=output_empty_metrics;
m2=output_launch_docker_metrics;
m3=output_launch_dockerhadoop_metrics;
m4=output_launch_dockerhadoopprogram_metrics;
m=m1;
null_metrics=Reduce(intersect,list(t1,t2,t3,t4));
used_metrics= setdiff(m,null_metrics);
# [1] "br0.net.rxkb.dat"      "br0.net.rxpck.dat"     "br0.net.txkb.dat"      "br0.net.txpck.dat"     "cpu.busy.dat"          "cpu.idle.dat"
# [7] "cpu.iowait.dat"        "cpu.system.dat"        "cpu.user.dat"          "disk.brdps.dat"        "disk.bwrps.dat"        "disk.rtps.dat"
# [13] "disk.tps.dat"          "disk.wtps.dat"         "docker0.net.rxkb.dat"  "docker0.net.rxpck.dat" "docker0.net.txkb.dat"  "docker0.net.txpck.dat"
# [19] "eth0.net.rxkb.dat"     "eth0.net.rxmcst.dat"   "eth0.net.rxpck.dat"    "eth0.net.txkb.dat"     "eth0.net.txpck.dat"    "eth1.net.rxkb.dat"
# [25] "eth1.net.rxmcst.dat"   "eth1.net.rxpck.dat"    "eth1.net.txkb.dat"     "eth1.net.txpck.dat"    "mem.commit.dat"        "mem.kbbuffers.dat"
# [31] "mem.kbcached.dat"      "mem.kbcommit.dat"      "mem.kbmemfree.dat"     "mem.kbmemused.dat"     "mem.memused.dat"
for(null_metric in null_metrics){
file_patterns=c(paste(null_metric,"$",sep=""),paste(null_metric,".png$",sep=""))
for(file_pattern in file_patterns){
#data_files=list.files(path=basedir,pattern=file_pattern);
rm(list=ls(pattern=file_pattern));
}
}
setwd(old);
null_metrics
t4=output_launch_dockerhadoopprogram_null_metric;
t3=output_launch_dockerhadoop_null_metric;
t2=output_launch_docker_null_metric;
t1=output_empty_null_metric=null_metric;
m1=output_empty_metrics;
m2=output_launch_docker_metrics;
m3=output_launch_dockerhadoop_metrics;
m4=output_launch_dockerhadoopprogram_metrics;
m=m1;
null_metrics=Reduce(intersect,list(t1,t2,t3,t4));
null_metrics
null_metrics=Reduce(intersect,list(t1,t2,t3,t4));
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
#file_patterns=c("output_launch_docker_1.txt.*.dat$","output_launch_docker_2.txt.*.dat$","output_launch_docker_3.txt.*.dat$")
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
name=paste("output_empty",name1,sep=".");
#name=paste("output_launch_docker",name1,sep=".");
metrics=append(metrics,name1);
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
x_axis=seq(0,28,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_empty_null_metric=null_metric;
output_empty_metrics=metrics;
setwd(old);
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
file_patterns=c("output_launch_docker_1.txt.*.dat$","output_launch_docker_2.txt.*.dat$","output_launch_docker_3.txt.*.dat$")
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_docker",name1,sep=".");
metrics=append(metrics,name1);
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,58,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_docker_null_metric=null_metric;
output_launch_docker_metrics=metrics;
setwd(old);
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
file_patterns=c("output_launch_dockerhadoop_1.txt.*.dat$","output_launch_dockerhadoop_2.txt.*.dat$","output_launch_dockerhadoop_3.txt.*.dat$")
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_dockerhadoop",name1,sep=".");
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
metrics=append(metrics,name1);
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,58,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_dockerhadoop_null_metric=null_metric;
output_launch_dockerhadoop_metrics=metrics;
setwd(old);
#!/usr/bin/Rscript
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
#file_patterns=c("output_empty.txt.*.dat$","output_empty_2.txt.*.dat$","output_empty_3.txt.*.dat$")
#file_patterns=c("output_launch_dockerhadoopprogram_1.txt.*.dat$","output_launch_dockerhadoopprogram_2.txt.*.dat$","output_launch_dockerhadoopprogram_3.txt.*.dat$","output_launch_dockerhadoopprogram_4.txt.*.dat$")
file_patterns=c("output_launch_dockerhadoopprogram_1.txt.*.dat$","output_launch_dockerhadoopprogram_2.txt.*.dat$","output_launch_dockerhadoopprogram_4.txt.*.dat$")
#discard experiment 3
XC=list();
for(file_pattern in file_patterns){
data_files=list.files(path=basedir,pattern=file_pattern);
#print(data_files)
X=list();
for(data_file in data_files){
data=as.numeric(readLines(data_file));
X=cbind(X,data);
}
X=as.data.frame(X);
colnames(X)=data_files;
XC[[file_pattern]]=X
}
null_metric=vector();
metrics=vector();
for(col_num in 1:length(X)){
name=data_files[col_num];
name1=strsplit(name,"txt.")[[1]][2];
# name=paste("output_empty",name1,sep=".");
name=paste("output_launch_dockerhadoopprogram",name1,sep=".");
metrics=append(metrics,name1);
#print(col_num)
value1=as.vector(XC[[1]][[col_num]]);
value2=as.vector(XC[[2]][[col_num]]);
value3=as.vector(XC[[3]][[col_num]]);
#v=as.matrix(cbind(value1,value2,value3));
v=as.matrix(cbind(as.numeric(value1),as.numeric(value2),as.numeric(value3)));
average=apply(v,1,mean);
v_max=max(apply(v,1,max));
v_min=min(apply(v,1,min));
if(v_max==v_min){
null_metric=append(null_metric,name1);
}
#x_axis=seq(0,28,2);
x_axis=seq(0,178,2);
# postscript(paste(getwd(),paste(name,"eps",sep="."),sep="/"));
png(paste(getwd(),paste(name,"png",sep="."),sep="/"));
# print(average)
# print(value1)
plot(x=x_axis,y=average,ylim=c(v_min,v_max),type="p",pch=4,cex=0.4,xlab="time(seconds)",ylab=name1,col="black");
lines(x=x_axis,y=average,col="black",lwd=2);
points(x=x_axis,y=average,type="p",pch=3,cex=0.4,xlab="time(seconds)",ylab="experiment1",col="black");
lines(x=x_axis,y=value1,col="red",lty=2);
points(x=x_axis,y=value2,type="p",pch=8,cex=0.4,xlab="time(seconds)",ylab="experiment2",col="black");
lines(x=x_axis,y=value2,col="green",lty=2);
points(x=x_axis,y=value3,type="p",pch=24,cex=0.4,xlab="time(seconds)",ylab="experiment3",col="black");
lines(x=x_axis,y=value3,col="blue",lty=2);
dev.off();
}
print(null_metric);
output_launch_dockerhadoopprogram_null_metric=null_metric;
output_launch_dockerhadoopprogram_metrics=metrics;
setwd(old);
old=getwd();
basedir="/home/peipei/course/CSC547/experiment_docker_hadoop";
setwd(basedir);
t4=output_launch_dockerhadoopprogram_null_metric;
t3=output_launch_dockerhadoop_null_metric;
t2=output_launch_docker_null_metric;
t1=output_empty_null_metric=null_metric;
m1=output_empty_metrics;
m2=output_launch_docker_metrics;
m3=output_launch_dockerhadoop_metrics;
m4=output_launch_dockerhadoopprogram_metrics;
m=m1;
null_metrics=Reduce(intersect,list(t1,t2,t3,t4));
used_metrics= setdiff(m,null_metrics);
# [1] "br0.net.rxkb.dat"      "br0.net.rxpck.dat"     "br0.net.txkb.dat"      "br0.net.txpck.dat"     "cpu.busy.dat"          "cpu.idle.dat"
# [7] "cpu.iowait.dat"        "cpu.system.dat"        "cpu.user.dat"          "disk.brdps.dat"        "disk.bwrps.dat"        "disk.rtps.dat"
# [13] "disk.tps.dat"          "disk.wtps.dat"         "docker0.net.rxkb.dat"  "docker0.net.rxpck.dat" "docker0.net.txkb.dat"  "docker0.net.txpck.dat"
# [19] "eth0.net.rxkb.dat"     "eth0.net.rxmcst.dat"   "eth0.net.rxpck.dat"    "eth0.net.txkb.dat"     "eth0.net.txpck.dat"    "eth1.net.rxkb.dat"
# [25] "eth1.net.rxmcst.dat"   "eth1.net.rxpck.dat"    "eth1.net.txkb.dat"     "eth1.net.txpck.dat"    "mem.commit.dat"        "mem.kbbuffers.dat"
# [31] "mem.kbcached.dat"      "mem.kbcommit.dat"      "mem.kbmemfree.dat"     "mem.kbmemused.dat"     "mem.memused.dat"
for(null_metric in null_metrics){
file_patterns=c(paste(null_metric,"$",sep=""),paste(null_metric,".png$",sep=""))
for(file_pattern in file_patterns){
#data_files=list.files(path=basedir,pattern=file_pattern);
rm(list=ls(pattern=file_pattern));
}
}
setwd(old);
null_metrics
